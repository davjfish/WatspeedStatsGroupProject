{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "suKaW-0xGRlv",
    "ExecuteTime": {
     "end_time": "2024-04-01T02:26:33.621105300Z",
     "start_time": "2024-04-01T02:26:29.029309900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import logit\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M70WHZ-EGRlw"
   },
   "source": [
    "COORDINATION / UPDATE NOTES\n",
    "\n",
    "* I created a Logistical regression model (create_model function) and applied it to transformed training data (pivoted the original dataset on the basis of customers, dropped some of the less-purchased items to balance out the dataset under the rule of 10); also created top_5 function to output top 5 product recommendations based on that model. -- Zac (3/27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ixrpH7wgGRlw",
    "ExecuteTime": {
     "end_time": "2024-04-01T02:27:44.677438300Z",
     "start_time": "2024-04-01T02:26:33.629434900Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load in the retail data\n",
    "df = pd.read_excel(\"../data/Online Retail.xlsx\")\n",
    "\n",
    "#Cut the size of the df to make it less cumbersome\n",
    "df = df.iloc[:9000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ueXXC-yGRlw"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FUNCTIONS\n",
    "\n",
    "Functions to perform various analytic/transformation tasks\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_model(df, item):\n",
    "    \"\"\"\n",
    "    Inputs the transaction dataframe and specific stock item (by ID) and outputs five top recommended purchases based on transaction data\n",
    "\n",
    "    NOTE: This is a work in progress; haven't been able to overcome perfect separation problems + R2s of 1, speak nothing of the slow speed for fitting.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Get the predictors\n",
    "    predictors = list(df.columns)\n",
    "    predictors.remove(item)\n",
    "\n",
    "    df['intercept'] = 1.0\n",
    "\n",
    "    #Create the model\n",
    "    m = Logit(df[item], df[predictors])\n",
    "    m = m.fit(maxiter=1000, method='bfgs')\n",
    "    #m = m.fit_regularized(maxiter=1000, method=\"l1\")\n",
    "\n",
    "    return m\n",
    "\n",
    "def top_5(fitted_model, df):\n",
    "    \"\"\"\n",
    "    Inputs fitted model from create_model, prints top 5 recommendations based on that item.\n",
    "    \"\"\"\n",
    "    t5i = list(fitted_model.params.sort_values(key=abs, ascending=False).iloc[1:].head(5).index)\n",
    "\n",
    "    for no, x in enumerate(t5i):\n",
    "        print(F'RECOMMENDATION #{no + 1}: ', df[df['StockCode'] == x].iloc[0]['Description'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwgcQYHaGRlx"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PREPARING THE DATA\n",
    "\n",
    "In this section we adjust the datatypes and create new data points as needed.\n",
    "\"\"\"\n",
    "\n",
    "#Total money spent in each purchase\n",
    "df['TotalSpend'] = df.apply(lambda row: row.UnitPrice * row.Quantity, axis=1)\n",
    "\n",
    "# Remove abnormal stock codes (Post, D, DOT, etc)\n",
    "mask1 = df['StockCode'].str.contains(r'[a-zA-Z]', regex=True, na=False)\n",
    "mask2 = df['StockCode'].str.match(r'^[^0-9]', na=False)\n",
    "df = df[~mask2]\n",
    "\n",
    "#Pivot the dataframe to focus on customer behavior\n",
    "df['Purchased'] = 1 #Adds a binary column for the pivot\n",
    "client_df1 = df.pivot_table(index='CustomerID', columns='StockCode', values='Purchased', aggfunc='max', fill_value=0)\n",
    "\n",
    "#Create a reference to determine the customers making the most purchases.\n",
    "client_df1['PurchaseNo'] = client_df1.apply(lambda row: row.sum(), axis=1)\n",
    "\n",
    "#RULE OF 10 - shave off some customers who don't make a lot of purchases in order to rectify the feature/column ratio\n",
    "cutoff_point = 15 # No. of purchases to serve as cutoff threshold for training data\n",
    "client_df1 = client_df1[client_df1['PurchaseNo'] > 12]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJJCFRBwGRlx"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXAMINING THE DATA\n",
    "\n",
    "In this section we see what we have with the data set.\n",
    "\"\"\"\n",
    "#DATAFRAME IN GENERAL\n",
    "#How many df entries in total? - 541909\n",
    "transaction_no = len(df)\n",
    "\n",
    "#How many customers in total? - 4373\n",
    "customer_no = len(df['CustomerID'].unique())\n",
    "\n",
    "#How many transactions in total? - 25900\n",
    "transaction_no = len(df['InvoiceNo'].unique())\n",
    "\n",
    "\n",
    "#INDIVIDUAL CUSTOMERS\n",
    "#Average individual customer spend (those that spent money/did not get refunds) - 1923.48\n",
    "customer_spend = df.groupby('CustomerID')['TotalSpend'].aggregate('sum')\n",
    "customer_spend = customer_spend[customer_spend > 0]\n",
    "avg_spend = np.mean(customer_spend).round(2)\n",
    "\n",
    "#PRODUCTS\n",
    "# How many products in total? - 4070\n",
    "product_no = len(df['StockCode'].unique())\n",
    "\n",
    "#Value counts of various products (possible grouping less popular items as 'other' on the basis of how many times they appear)\n",
    "prod_counts = df['StockCode'].value_counts()\n",
    "#print(len(prod_counts[prod_counts < 15]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Er3wcqfGGRlx",
    "outputId": "d97acb6a-4419-43b7-edda-ff81ba9cf3e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 24\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natur\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "EXECUTING THE MODEL\n",
    "\n",
    "In this section we apply the model to the data set.\n",
    "\"\"\"\n",
    "\n",
    "#This creates the model based on one product - StockCode 84380 - in the hope of eventually outputting the five most suitable product recommendations based on customers cross-purchasing.\n",
    "m = create_model(client_df1, 84380)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9r563r19GRlx",
    "outputId": "a50587b5-3d4b-4ede-a276-35b5d49b160b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECOMMENDATION #1:  PACK OF 72 SKULL CAKE CASES\n",
      "RECOMMENDATION #2:  PAPER CHAIN KIT 50'S CHRISTMAS \n",
      "RECOMMENDATION #3:  HEART OF WICKER LARGE\n",
      "RECOMMENDATION #4:  JUMBO STORAGE BAG SUKI\n",
      "RECOMMENDATION #5:  SET 6 FOOTBALL CELEBRATION CANDLES\n"
     ]
    }
   ],
   "source": [
    "top_5(m, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRsa0UAwGRlx",
    "outputId": "6e8e5c08-af83-491a-a6a7-140a797c7b01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTESTING THE MODEL\\n\\nIn this section we discern the accuracy of the model.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING THE MODEL\n",
    "\n",
    "In this section we discern the accuracy of the model.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
