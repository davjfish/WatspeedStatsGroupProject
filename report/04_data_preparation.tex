\section{Data Preparation}

\subsection{What was your data source?}

Three datasets were used in this analysis.

The first, as noted above, was the Government of Canada's Open Government Portal~\cite{ogp}.
The name of the dataset is NAFO Division 4T groundfish research vessel trawl survey (September Survey) dataset~\cite{groundfish}.
The dataset contained information ecological information (i.e., species caught, specimen counts and specimen weights),
fishing information (i.e., gear type used, fishing vessel) and spatial information (i.e., latitude and longitude).
For mapping purposes, I also used a geospatial file of the Canada Provincial Boundaries from the same catalogue~\cite{canmap}.

The dataset did not contain and elevation data and therefore this had to be acquired elsewhere.
Luckily, there is an excellent website and web app called the General bathymetric Chart of the Oceans (GEBCO),
which is maintained by the international community~\cite{gebco}.
The web app provides an interface for downloading world ocean's bathymetric data.

\subsection{How good was the data quality?}

The quality of the fishing data was excellent.
There were no missing values and the column data types were respected.
For example, the columns that you would expect to be \textit{float} type, e.g., lat/lon values, were indeed.
The dataset was accompanied by a data dictionary, which contained clear explanation of the variables in both English and French.
The only thing worth mentioning was that the coordinate reference system for the latitudes and longitudes were difficult to obtain.
They are not displayed on the website but the metadata XML file did specify EPSG 4269.

\subsection{What did you need to do to procure it?}

The data from the Open Government Portal was downloaded using a web browser.
The data was accessible via a static link.
The format of the fishing data was a single comma separated values (CSV) document and the map was formatted as a GEOJSON file.
The GEBCO elevation data was downloaded using their customizable web application.
In this application, I was able to download the bathymetric data as a NetCDF file for only the area of interest.
I was very impressed with this tool!


\subsection{What tools or code did you need to use to prepare it for analysis?}


\subsubsection{Fishing Data}

As noted above, the species / fishing data was very clean.
I loaded the data from its original CSV into a pandas dataframe.
I ensured all the data types made sense using the \textbf{DataFrame.info()} method.

\subsubsection{Mapping Data}



\subsubsection{Elevation Data}



\subsection{What challenges did you face?}

Since geographic information systems is not my area of expertise, I found it challenging figuring out how to reproject a geographical data to another
coordinate reference system.
In the end, this was not too difficult, but it took time to figure out.

Another major challenge was learning about the Xarray python package~\cite{xarray}.
This is a very impressive package, albeit quite complex.
It took me a long time to figure out how to extract the data from a data array, manipulate it and create a new data array.





\begin{figure}
    \includegraphics[width=\linewidth]{merged_graph}
    \caption{This figure shows the raw data, and aggregated forms of Chicken Meat, Hogs and Wheat.}
    \label{fig:chicken_prices}
\end{figure}

